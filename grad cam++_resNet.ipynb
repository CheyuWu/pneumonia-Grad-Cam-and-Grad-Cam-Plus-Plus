{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import load_img #import image need this\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense,Input,BatchNormalization,AveragePooling2D\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D,Conv2D\n",
    "from keras.applications import VGG16\n",
    "from keras.applications import VGG19\n",
    "from keras.applications import ResNet50\n",
    "from keras.applications import MobileNetV2\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "import  tensorflow as  tf\n",
    "import keras.backend as K\n",
    "import os\n",
    "import random\n",
    "import scipy\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix,roc_curve,roc_auc_score,auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def history_plot(results,img_name): \n",
    "    # list all data in history\n",
    "    print(results.history.keys())\n",
    "    # summarize history for accuracy\n",
    "    plt.figure(1)\n",
    "    plt.plot(results.history['acc'])\n",
    "    plt.plot(results.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.savefig('Accuracy_'+img_name,dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    # summarize history for loss\n",
    "    plt.figure(2)\n",
    "    plt.plot(results.history[\"loss\"], label=\"loss\")\n",
    "    plt.plot(results.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.plot(np.argmin(results.history[\"val_loss\"]), \n",
    "             np.min(results.history[\"val_loss\"]), \n",
    "             marker=\"x\", color=\"r\", label=\"best model\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"log_loss\")\n",
    "    plt.legend();\n",
    "    plt.savefig('Loss_'+img_name ,dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flow_from_directory目錄需要分3類\n",
    "train_image = './pneu_dataset/train'\n",
    "valid_image = './pneu_dataset/validation'\n",
    "test_image = './pneu_dataset/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the default value\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 229, 229\n",
    "batch_size = 32\n",
    "epochs = 700\n",
    "seed = 42\n",
    "class_mode = 'categorical'\n",
    "date = '2019-06-23_resNet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ImageDataGenerator\n",
    "# used to rescale the pixel values from [0, 255] to [0, 1] interval\n",
    "datagen = ImageDataGenerator(rescale=1./255,\n",
    "                             rotation_range = 180)  #圖片隨機轉動\n",
    "#                              width_shift_range = 0.2, #圖片水平偏移\n",
    "#                              height_shift_range = 0.2, #圖片垂直偏移\n",
    "#                              zoom_range = 0.3)\n",
    "\n",
    "# automagically retrieve images and their classes for train and validation sets\n",
    "train_generator = datagen.flow_from_directory(\n",
    "       train_image,\n",
    "        target_size = (img_width, img_height),\n",
    "        batch_size = batch_size,\n",
    "        shuffle=True,\n",
    "        class_mode = class_mode,\n",
    "        seed = seed)\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "        valid_image,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode = class_mode,\n",
    "        shuffle = False ,\n",
    "        seed = seed)\n",
    "\n",
    "# test_generator = datagen.flow_from_directory(\n",
    "#         test_image,\n",
    "#         target_size = (img_width, img_height),\n",
    "#         batch_size = 1,\n",
    "#         class_mode = None,\n",
    "#         shuffle = False,\n",
    "#         seed = seed\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #resent50架構\n",
    "# def conv_block(input_tensor, kernel_size, filters, stage, block, strides):\n",
    "#     \"\"\"conv_block is the block that has a conv layer at shortcut\n",
    "#     # Arguments\n",
    "#         input_tensor: input tensor 等於x\n",
    "#         kernel_size: (3x3大小) defualt 3, the kernel size of middle conv layer at main path\n",
    "#         filters: (利用list傳入) list of integers, the filterss of 3 conv layer at main path\n",
    "#         stage: integer, current stage label, used for generating layer names\n",
    "#         block: 'a','b'..., current block label, used for generating layer names \n",
    "#     # Returns\n",
    "#         Output tensor for the block.\n",
    "#     Note that from stage 3, the first conv layer at main path is with strides=(2,2)\n",
    "#     And the shortcut should have strides=(2,2) as well\n",
    "#     \"\"\"\n",
    "#     #串列把數值給3個變數\n",
    "#     filters1, filters2, filters3 = filters\n",
    "#     if K.image_data_format() == 'channels_last':\n",
    "#         bn_axis = 3\n",
    "#     else:\n",
    "#         bn_axis = 1\n",
    "#     conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "#     bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    " \n",
    "#     x = Conv2D(filters1, kernel_size=(3, 3), strides=strides, padding='same',name=conv_name_base + '2a')(input_tensor)             \n",
    "#     x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "#     x = Activation('relu')(x)\n",
    " \n",
    "#     x = Conv2D(filters2, kernel_size=(3, 3),strides=strides, padding='same',name=conv_name_base + '2b')(x)               \n",
    "#     x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "#     x = Activation('relu')(x)\n",
    " \n",
    "#     x = Conv2D(filters3, kernel_size=(3, 3),strides=strides,padding='same',name=conv_name_base + '2c')(x)\n",
    "#     x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    " \n",
    "#     shortcut = Conv2D(filters3, kernel_size=(3, 3), strides=strides, padding='same',name=conv_name_base + '1')(x)                     \n",
    "#     shortcut = BatchNormalization(axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
    " \n",
    "#     #加入2個路徑 一個是正常 一個是最短路徑 電腦會自動選擇最佳路徑\n",
    "#     x = layers.add([x, shortcut])\n",
    "#     x = Activation('relu')(x)\n",
    "#     return x\n",
    "\n",
    "# def identity_block(input_tensor, kernel_size, filters, stage, block,strides):\n",
    "#     \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
    "#     # Arguments\n",
    "#         input_tensor: input tensor  #输入变量#\n",
    "#         kernel_size: defualt 3, the kernel size of middle conv layer at main path #卷积核的大小#\n",
    "#         filters: list of integers, the filterss of 3 conv layer at main path  #卷积核的数目#\n",
    "#         stage: integer, current stage label, used for generating layer names #当前阶段的标签#\n",
    "#         block: 'a','b'..., current block label, used for generating layer names #当前块的标签#\n",
    "#     # Returns\n",
    "#         Output tensor for the block.  \n",
    "#     \"\"\"\n",
    "#     filters1, filters2, filters3 = filters  #滤波器的名称#\n",
    "#     if K.image_data_format() == 'channels_last':  #代表图像通道维的位置#\n",
    "#         bn_axis = 3\n",
    "#     else:\n",
    "#         bn_axis = 1\n",
    "#     conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "#     bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    " \n",
    "#     x = Conv2D(filters1, kernel_size=(3, 3),strides=strides,padding='same',name=conv_name_base + '2a')(input_tensor)\n",
    "#     x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "#     x = Activation('relu')(x)   #卷积层，BN层，激活函数#\n",
    " \n",
    "#     x = Conv2D(filters2, kernel_size=(3, 3),strides=strides,padding='same', name=conv_name_base + '2b')(x)               \n",
    "#     x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "#     x = Activation('relu')(x)\n",
    " \n",
    "#     x = Conv2D(filters3, kernel_size=(3, 3),strides=strides, padding='same',name=conv_name_base + '2c')(x)\n",
    "#     x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    " \n",
    "#     x = layers.add([x, x])\n",
    "#     x = Activation('relu')(x)\n",
    "#     return x\n",
    "\n",
    "# # model = ResNet50(include_top=False,weights='imagenet',input_shape=(img_width,img_height,3))\n",
    "# input_tensor = Input(shape=(img_width, img_height, 3))\n",
    "# #3x3的濾鏡大小\n",
    "# x = ZeroPadding2D((3, 3))(input_tensor)\n",
    "# x = Conv2D(nb_filter=64, kernel_size=(7, 7), strides=(2, 2), padding='valid', activation='relu', name='conv1')(x)\n",
    "# x = BatchNormalization(axis=3, name='bn_conv1')(x)\n",
    "# x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
    "# #stage2#\n",
    "# x = conv_block(x, kernel_size=(3, 3), filters=[64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
    "# x = identity_block(x, kernel_size=(3, 3),filters=[64, 64, 256], stage=2, block='b',strides=(1, 1))\n",
    "# x = identity_block(x, kernel_size=(3, 3),filters=[64, 64, 256], stage=2, block='c',strides=(1, 1))\n",
    "\n",
    "\n",
    "# #stage3#\n",
    "# x = conv_block(x, kernel_size=(3, 3), filters=[128, 128, 512], stage=3, block='a', strides=(1, 1))\n",
    "# x = identity_block(x, kernel_size=(3, 3), filters=[128, 128, 512], stage=3, block='b', strides=(1, 1))\n",
    "# x = identity_block(x, kernel_size=(3, 3), filters=[128, 128, 512], stage=3, block='c', strides=(1, 1))\n",
    "# x = identity_block(x, kernel_size=(3, 3), filters=[128, 128, 512], stage=3, block='d', strides=(1, 1))\n",
    "# #stage4#\n",
    "# x = conv_block(x, kernel_size=(3, 3), filters=[256, 256, 1024], stage=4, block='a', strides=(1, 1))\n",
    "# x = identity_block(x, kernel_size=(3, 3), filters=[256, 256, 1024], stage=4, block='b', strides=(1, 1))\n",
    "# x = identity_block(x, kernel_size=(3, 3), filters=[256, 256, 1024], stage=4, block='c', strides=(1, 1))\n",
    "# x = identity_block(x, kernel_size=(3, 3), filters=[256, 256, 1024], stage=4, block='d', strides=(1, 1))\n",
    "# x = identity_block(x, kernel_size=(3, 3), filters=[256, 256, 1024], stage=4, block='e', strides=(1, 1))\n",
    "# x = identity_block(x, kernel_size=(3, 3), filters=[256, 256, 1024], stage=4, block='f', strides=(1, 1))\n",
    "# #stage5#\n",
    "# x = conv_block(x, kernel_size=(3, 3), filters=[512, 512, 2048], stage=5, block='a', strides=(1, 1))\n",
    "# x = identity_block(x, kernel_size=(3, 3), filters=[512, 512, 2048], stage=5, block='b', strides=(1, 1))\n",
    "# x = identity_block(x, kernel_size=(3, 3), filters=[512, 512, 2048], stage=5, block='c', strides=(1, 1))\n",
    "\n",
    "# x_fc = AveragePooling2D(pool_size=(7, 7))(x)\n",
    "# x_fc = Flatten()(x_fc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_net = Model(inputs=input_tensor,outputs=x_fc)\n",
    "# model_net.load_weights('./resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "# model = Dense(3, activation='softmax')(model_net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ResNet50(include_top=False,weights='imagenet',input_shape=(img_width,img_height,3))\n",
    "x= net.output\n",
    "x = Flatten()(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "output_layer = Dense(3, activation='softmax', name='softmax')(x)\n",
    "model = Model(inputs=net.input, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=1e-6),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定checkpoint & callbacks\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "def callbacks(name):\n",
    "    save_dir = \"checkpoint\"\n",
    "    #     tl.files.exists_or_mkdir(save_dir)\n",
    "    path=save_dir+'/model_check_'+name+'.h5'\n",
    "    callbacks = [\n",
    "        EarlyStopping(patience=25, verbose=1),\n",
    "        ReduceLROnPlateau(factor=0.1, patience=10, min_lr=0.000001, verbose=1),\n",
    "        ModelCheckpoint(path, verbose=1, save_best_only=True, save_weights_only=False)\n",
    "#         ModelCheckpoint(path,monitor='val_acc', verbose=1,\n",
    "#                         save_best_only=True, save_weights_only=False)\n",
    "    ]\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_train_samples  = train_generator.classes.shape[0]\n",
    "num_of_test_samples = validation_generator.classes.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch= num_of_train_samples//batch_size,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps= num_of_test_samples//batch_size,\n",
    "        epochs = epochs,\n",
    "        callbacks=callbacks(date+'_fit'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_plot(history,'resNet50.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CheckPoint\n",
    "from keras.models import load_model\n",
    "model= load_model('./checkpoint/model_check_2019-06-23_resNet_fit.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "model.evaluate_generator(generator=validation_generator,\n",
    "#                          steps=validation_generator.classes.shape[0]//32 +1,\n",
    "                         steps=validation_generator.classes.shape[0],\n",
    "                         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# predict the output\n",
    "Y_pred = model.predict_generator(validation_generator,\n",
    "                                 steps=num_of_test_samples//32 +1,\n",
    "                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use auc to show the performance\n",
    "auc = roc_auc_score(validation_generator.classes,Y_pred)\n",
    "print(\"AUC: {}\".format(auc))\n",
    "# fpr, tpr, thresholds = roc_curve(validation_generator.classes, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curve\n",
    "plt.figure(3)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr,tpr,label='AUC = %0.2f' % auc)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "# plt.show()\n",
    "plt.savefig(\"roc_curve.png\",dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "# from keras.models import load_model \n",
    "# base_model= load_model('./checkpoint/model_check_2019-06-16_VGG16_fit.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = {'png', 'retina'}\n",
    "plt.rcParams['figure.figsize'] = 8,8\n",
    "\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "\n",
    "import os\n",
    "import gradcamutils # source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_predictions_cust(preds, class_custom, top=3):\n",
    "    results = []\n",
    "    for pred in preds:\n",
    "        top_indices = pred.argsort()[-top:][::-1]\n",
    "        result = [tuple(class_custom[i][0])+(class_custom[i][1],) + (pred[i]*100,)\\\n",
    "                  for i in top_indices] \n",
    "        results.append(result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "class_name=[('0','Lung Opacity'),('1','Normal'),('2','Not Normal')]\n",
    "label = [] # label Lung Opacity, Normal, Not Normal\n",
    "# path of img \n",
    "valid_lung_op_path='./pneu_dataset/validation/Lung Opacity/'\n",
    "valid_normal_path='./pneu_dataset/validation/Normal/'\n",
    "valid_not_normal_path='./pneu_dataset/validation/Not Normal/'\n",
    "paths = [valid_lung_op_path,valid_normal_path,valid_not_normal_path]\n",
    "# list of each img\n",
    "valid_path = []\n",
    "# dir \n",
    "for path in paths:\n",
    "    for file in  os.listdir(path):\n",
    "        if path == './pneu_dataset/validation/Lung Opacity/':\n",
    "            valid_path.append(path+file)\n",
    "            label.append('Lung Opacity')\n",
    "        elif path == './pneu_dataset/validation/Normal/':\n",
    "            valid_path.append(path+file)\n",
    "            label.append('Normal')\n",
    "        elif path == './pneu_dataset/validation/Not Normal/':\n",
    "            valid_path.append(path+file)\n",
    "            label.append('Not Normal')\n",
    "        else :\n",
    "            label.append('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grad cam \n",
    "for path in valid_path:\n",
    "    \n",
    "    count+=1\n",
    "    if count <= 0:\n",
    "        pass\n",
    "    else :\n",
    "        orig_img = np.array(load_img(path,target_size=(229,229)),dtype=np.uint8)\n",
    "        img = np.array(load_img(path,target_size=(229,229)),dtype=np.float64)\n",
    "        img = np.expand_dims(img,axis=0)\n",
    "        img = preprocess_input(img)\n",
    "        predictions = model.predict(img)\n",
    "        top_n = 3\n",
    "        top = decode_predictions_cust(predictions,class_name ,top=top_n)[0]\n",
    "    #     top = decode_predictions(predictions, top=top_n)[0]\n",
    "        cls = np.argsort(predictions[0])[-top_n:][::-1]\n",
    "\n",
    "        gradcam=gradcamutils.grad_cam(model,img,layer_name='res5c_branch2c')\n",
    "        gradcamplus=gradcamutils.grad_cam_plus(model,img,layer_name='res5c_branch2c')\n",
    "        print(path)\n",
    "        print(\"class activation map for:\",top[0])\n",
    "        fig, ax = plt.subplots(nrows=1,ncols=3)\n",
    "        plt.subplot(131)\n",
    "        plt.imshow(orig_img)\n",
    "        plt.title(\"input image \\n\"+'('+str(label[count])+')')\n",
    "\n",
    "        plt.subplot(132)\n",
    "        plt.imshow(orig_img)\n",
    "        plt.imshow(gradcam,alpha=0.8,cmap=\"jet\")\n",
    "        plt.title(\"Grad-CAM \\n\"+str(top[0][1])+'\\n'+str(top[0][2])[:6])\n",
    "\n",
    "        plt.subplot(133)\n",
    "        plt.imshow(orig_img)\n",
    "        plt.imshow(gradcamplus,alpha=0.8,cmap=\"jet\")\n",
    "        plt.title(\"Grad-CAM++ \\n\"+str(top[0][1])+'\\n'+str(top[0][2])[:6])\n",
    "        plt.savefig('./grad_cam_image/resNet/resNet_'+str(count)+'.png',dpi=300)\n",
    "    #     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # grad cam  \n",
    "# def grad_CAM(image_path):\n",
    "#     im = load_img(image_path, target_size=(299,299))\n",
    "#     x = preprocess_input(im)\n",
    "#     x = base_model.predict(x)\n",
    "#     pred = model.predict(x)\n",
    "    \n",
    "#     # Predicted class index\n",
    "#     index = np.argmax(pred)\n",
    "    \n",
    "#     # Get the entry of the predicted class\n",
    "#     class_output = model.output[:, index]\n",
    "    \n",
    "#     # The last convolution layer in the model\n",
    "#     last_conv_layer = model.get_layer('conv2d_1')\n",
    "#     # Number of channels\n",
    "#     nmb_channels = last_conv_layer.output.shape[3]\n",
    "\n",
    "#     # Gradient of the predicted class with respect to the output feature map of the \n",
    "#     # the convolution layer with nmb_channels channels\n",
    "#     grads = K.gradients(class_output, last_conv_layer.output)[0] \n",
    "    \n",
    "    \n",
    "#     # Vector of shape (nmb_channels,), where each entry is the mean intensity of the gradient over \n",
    "#     # a specific feature-map channel”\n",
    "#     pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "#     # Setup a function to extract the desired values\n",
    "#     iterate = K.function(model.inputs, [pooled_grads, last_conv_layer.output[0]])\n",
    "#     # Run the function to get the desired calues\n",
    "#     pooled_grads_value, conv_layer_output_value = iterate([x])\n",
    "    \n",
    "    \n",
    "#     # Multiply each channel in the feature-map array by “how important this channel is” with regard to the \n",
    "#     # predicted class\n",
    "#     for i in range(nmb_channels):\n",
    "#         conv_layer_output_value[:, :, i] *= pooled_grads_value[i]\n",
    "#     # The channel-wise mean of the resulting feature map is the heatmap of the class activation.\n",
    "#     heatmap = np.mean(conv_layer_output_value, axis=-1)   \n",
    "    \n",
    "#     # Normalize the heatmap betwen 0 and 1 for visualization\n",
    "#     heatmap = np.maximum(heatmap, 0)\n",
    "#     heatmap /= np.max(heatmap)\n",
    "    \n",
    "    \n",
    "#     # Read the image again, now using cv2\n",
    "#     img = cv2.imread(image_path)\n",
    "#     # Size the heatmap to the size of the loaded image\n",
    "#     heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "#     # Convert to RGB\n",
    "#     heatmap = np.uint8(255 * heatmap)\n",
    "#     # Pseudocolor/false color a grayscale image using OpenCV’s predefined colormaps\n",
    "#     heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    \n",
    "#     # Superimpose the image with the required intensity\n",
    "#     superimposed_img = heatmap * 0.5 + img   \n",
    "    \n",
    "#     # Write the image\n",
    "#     plt.figure(figsize=(24,12))\n",
    "#     cv2.imwrite('./tmp.jpg', superimposed_img)\n",
    "#     plt.imshow(mpimg.imread('./tmp.jpg'))\n",
    "#     plt.title(image_path)\n",
    "#     plt.show()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
